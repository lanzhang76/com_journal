{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building functions that allow adding and subtracting comedians from the corpus\n",
    "1. provide a dictionary of selections that contain their transcript index number \n",
    "2. asks for user input to select a name from the selections{}\n",
    "3. the comedian and all his transcripts will be added to the context dictionary \n",
    "4. using corpus function to generate a text that will be used to create our Markov Chain model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = {\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "selections = {\n",
    "    'bill maher': [0, 4, 8, 13, 15, 17, 91, 94, 102, 104],\n",
    "    'Sarah Silverman': [84],\n",
    "    'Aziz Ansari': [23],\n",
    "    'Jerry Seinfeld': [47], \n",
    "    'Amy Schumer': [49]   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'George Carlin: Saturday Night Live Monologue S01E01 (10/11/1975) â€“ Full Transcript'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file = pd.read_csv('../jan7/300Full_transcripts.csv')\n",
    "file.title[79]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "who you want to add?bill maher\n"
     ]
    }
   ],
   "source": [
    "name = input(\"who you want to add?\")\n",
    "if selections.get(name) is not None:\n",
    "    context[name] = [file.scripts[i] for i in selections.get(name)]\n",
    "    print(f\"{name} is added to the corpus\")\n",
    "else:\n",
    "    print('select again')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#context.pop('Jerry Seinfeld')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"\"\n",
    "for i in context:\n",
    "    for e in context[i]:\n",
    "        corpus += e\n",
    "corpus = corpus.replace('\\', \\'',' ').replace('\\']','').replace('[\\'','').replace('xa0',' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add a comedian's style from the selection to the current dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addToCorpus(csv_file,name):\n",
    "    file = pd.read_csv(csv_file)\n",
    "    if selections.get(name) is not None:\n",
    "        context[name] = [file.scripts[i] for i in selections.get(name)]\n",
    "        print(f\"{name} is added to the corpus\")\n",
    "    else:\n",
    "        print(\"your selection is incorrect. Try again\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amy Schumer is added to the corpus\n"
     ]
    }
   ],
   "source": [
    "addToCorpus('../jan7/300Full_transcripts.csv','Amy Schumer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build a corpus from a dictionary of names and their transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def buildCorpus(context):\n",
    "    corpus = \"\"\n",
    "    for i in context:\n",
    "        for e in context[i]:\n",
    "            corpus += e\n",
    "    corpus = corpus.replace('\\', \\'',' ').replace('\\']','').replace('[\\'','').replace('xa0',' ').replace('\\\\','')\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## delete from the current dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delFromCorpus(context_dict,name):\n",
    "    try:\n",
    "        context_dict.pop(name)\n",
    "        print(f\"{name} is deleted from the dictionary\")\n",
    "    except:\n",
    "        print(f\"sorry, {name} is not in the dictionary. It cannot be deleted.\")\n",
    "        print(f\"{[i for i in context]} are in the dictionary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorry, Jerry is not in the dictionary. It cannot be deleted.\n",
      "['bill maher', 'Amy Schumer'] are in the dictionary.\n"
     ]
    }
   ],
   "source": [
    "delFromCorpus(context,'Jerry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bill maher', 'Amy Schumer']\n"
     ]
    }
   ],
   "source": [
    "print([e for e in [i for i in context]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
